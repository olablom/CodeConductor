name: CodeConductor Tests

on:
  pull_request:
    branches: [ main, develop ]
  push:
    branches: [ main ]

env:
  PYTHONHASHSEED: 0
  CODECONDUCTOR_SEED: 1337

jobs:
  test:
    runs-on: ubuntu-latest

    strategy:
      matrix:
        python-version: [3.11]

    steps:
    - uses: actions/checkout@v4

    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v4
      with:
        python-version: ${{ matrix.python-version }}

    - name: Install system dependencies
      run: |
        sudo apt-get update
        sudo apt-get install -y nvidia-cuda-toolkit

    - name: Cache pip dependencies
      uses: actions/cache@v3
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-

    - name: Install Python dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install pytest-json-report pytest-cov pytest-timeout

    - name: Run linting
      run: |
        pip install black flake8
        black --check src/
        flake8 src/ --max-line-length=88

    - name: Run unit tests with JSON report
      run: |
        python -m pytest tests/ -q --json-report --json-report-file .artifacts/report.json

    - name: Run tests with coverage
      run: |
        python -m pytest --cov=codeconductor --cov-config=.coveragerc --cov-report=term-missing --cov-report=html

    - name: Verify test results
      run: |
        mkdir -p .artifacts
        python - <<'PY'
        import json, sys
        try:
            d = json.load(open(".artifacts/report.json", "r", encoding="utf-8"))
            tests = d.get("tests", [])
            passed = len([t for t in tests if t.get("outcome") == "passed"])
            failed = len([t for t in tests if t.get("outcome") == "failed"])
            skipped = len([t for t in tests if t.get("outcome") == "skipped"])

            print(f"Test Results: {passed} passed, {failed} failed, {skipped} skipped")

            if failed > 0:
                print("❌ Tests failed!")
                sys.exit(1)

            print("✅ All tests passed!")

        except Exception as e:
            print(f"❌ Error reading test report: {e}")
            sys.exit(1)
        PY

    - name: Run master test suite
      run: |
        python test_master_simple.py --quick

    - name: Upload test report
      if: always()
      uses: actions/upload-artifact@v3
      with:
        name: test-report-linux
        path: .artifacts/report.json

    - name: Upload coverage HTML
      if: always()
      uses: actions/upload-artifact@v3
      with:
        name: coverage-html-linux
        path: htmlcov/

    - name: Upload test results
      uses: actions/upload-artifact@v3
      if: always()
      with:
        name: test-results
        path: |
          .artifacts/
          htmlcov/
          simple_master_test_results_*.json
          *.log

  benchmark:
    runs-on: ubuntu-latest
    needs: test

    steps:
    - uses: actions/checkout@v4

    - name: Set up Python 3.11
      uses: actions/setup-python@v4
      with:
        python-version: 3.11

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt

    - name: Run performance benchmarks
      run: |
        python tests/run_benchmarks.py --agent-count=2 --quick

    - name: Upload benchmark results
      uses: actions/upload-artifact@v3
      if: always()
      with:
        name: benchmark-results
        path: benchmark_results_*.json